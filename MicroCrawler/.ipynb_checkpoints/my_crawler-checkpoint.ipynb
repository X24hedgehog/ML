{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5620b786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\This PC\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# !pip install river\n",
    "# !pip install microprediction\n",
    "# !pip install numpy\n",
    "import numpy\n",
    "from river import linear_model\n",
    "from river import preprocessing\n",
    "from river import neighbors\n",
    "from river import neural_net as nn\n",
    "from river import metrics\n",
    "from river import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e9cb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_key = '7248d354a9e2a4aac6feb7dcc433acb1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deb4ffe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Var: 0."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from microprediction import MicroCrawler\n",
    "from microprediction import MicroReader\n",
    "import math \n",
    "import numpy as np\n",
    "import river.stats\n",
    "import collections\n",
    "import functools\n",
    "\n",
    "reader = MicroReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ca60b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCrawler(MicroCrawler):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "        self.freq = {}\n",
    "        self.var = {}\n",
    "        # dictionary saving models for datastream\n",
    "        self.model = {}\n",
    "        self.queue = {}\n",
    "        self.names = set()\n",
    "        self.count = {}\n",
    "        # Create 10 most used models for regression problems\n",
    "        model = preprocessing.StandardScaler()\n",
    "        contents = [linear_model.BayesianLinearRegression(), \n",
    "                    nn.MLPRegressor(hidden_dims=(5,),activations=(nn.activations.ReLU,nn.activations.ReLU,nn.activations.Identity),optimizer=optim.SGD(1e-3),seed=42)]\n",
    "        learning_rate = [0.01, 0.001, 0.0001, 0.1, 0.00001, 0.02, 0.2, 0.05] \n",
    "        for i in learning_rate:\n",
    "            contents.append(linear_model.LinearRegression(optimizer=optim.SGD(lr=i)))\n",
    "\n",
    "        models = [model | content for content in contents]\n",
    "        # 10 models to be chosen from\n",
    "        self.models = models\n",
    "        self.init_models = {}\n",
    "\n",
    "        for model in models:\n",
    "            self.count[model] = 0\n",
    "            \n",
    "        self.evaluate = {}\n",
    "        self.metric = {}\n",
    "        self.init_val = {}\n",
    "        self.init_model = {}\n",
    "           \n",
    "    def get_freq(self, frequency):\n",
    "        if frequency >= 86400:\n",
    "        # The frequency is bigger than a day, then seasonality should be weekly\n",
    "            return math.ceil(604800/frequency)\n",
    "        elif frequency >= 3600:\n",
    "        # The frequency is bigger than an hour but less tha a day, then seasonality should be hourly\n",
    "            return math.ceil(86400/frequency)\n",
    "        elif frequency >= 60:\n",
    "        # The frequency is bigger than a minute but less than an hour, then seasonality should be minute\n",
    "            return math.ceil(3600/frequency)\n",
    "        else:\n",
    "        # The frequency is less than a minute, then seasonality is second\n",
    "            return math.ceil(60/frequency)\n",
    "\n",
    "    def number_of_element_in_season(self, lagged_time_array):\n",
    "        if len(lagged_time_array) == 1:\n",
    "            return self.get_freq(lagged_time_array[0])\n",
    "        else:\n",
    "            return self.get_freq(lagged_time_array[0] - lagged_time_array[1])\n",
    "    \n",
    "        \n",
    "    def sample(self, lagged_values, lagged_times=None, name=None, delay=None, **ignored):\n",
    "        \"\"\" An example of a sample method. This is where all the intelligence goes\n",
    "               :param lagged_values [ float ]    List with most recent listed first\n",
    "               :param lagged_times [ float ]    List of epoch times, most recent listed first\n",
    "               :param name          str         Name of stream\n",
    "               :param delay         int         Prediction horizon in seconds\n",
    "               **ignored                        For future compatability.\n",
    "               :returns            [ float ]    A vector of numbers somewhat indicative of a probability density, of length self.num_predictions\n",
    "        \"\"\"\n",
    "        if name not in self.names:\n",
    "            self.names.add(name)\n",
    "            self.evaluate[name] = [0 for _ in range (10)]\n",
    "            self.metric[name] = [metrics.R2() for _ in range (10)]\n",
    "            self.init_val[name] = [[] for _ in range (10)]\n",
    "            self.init_model[name] = self.models\n",
    "            self.var[name] = river.stats.Var()\n",
    "\n",
    "        if name not in self.models:\n",
    "            self.freq[name] = self.number_of_element_in_season(lagged_times)\n",
    "            self.queue[name] = collections.deque(maxlen=self.freq[name])\n",
    "            for i in range (len(self.models)):\n",
    "            # Warm start\n",
    "                for x, y in zip(reversed(lagged_times), reversed(lagged_values)):\n",
    "                    new_feats = {f\"lag_{i}\": v for i, v in enumerate(self.queue[name])}\n",
    "\n",
    "                    if len(new_feats) < self.freq[name]:\n",
    "                        continue\n",
    "\n",
    "                    # copy of x\n",
    "                    x_ = {'time': x}\n",
    "                    x_.update(new_feats)\n",
    "\n",
    "                    y_pred = self.init_model[name][i].predict_one(x_)\n",
    "                    self.init_model[name][i].learn_one(x_, y)\n",
    "\n",
    "                    self.init_val[name][i].append((y, y_pred))\n",
    "                    self.metric[name][i].update(y, y_pred)\n",
    "                    self.queue[name].append(y)\n",
    "                    variance = self.var[name].update(y_pred).get()\n",
    "    \n",
    "            self.evaluate[name] = [metric.get() for metric in self.metric[name]]\n",
    "            temp = -1e9\n",
    "            t = 0\n",
    "            for i in range (10):\n",
    "                if self.evaluate[name][i] > temp:\n",
    "                    t = i\n",
    "                    temp = self.evaluate[name][i]\n",
    "            self.model[name] = self.models[t]\n",
    "\n",
    "        x = {f\"lag_{i}\": v for i, v in enumerate(self.queue[name])}\n",
    "        x[\"time\"] = lagged_times[0]\n",
    "        y = lagged_values[0]\n",
    "        self.model[name].learn_one(x, y)\n",
    "        self.queue[name].append(y)\n",
    "        x = {f\"lag_{i}\": v for i, v in enumerate(self.queue[name])}\n",
    "        x['time'] = 2*lagged_times[0] - lagged_times[1]\n",
    "        y_pred = self.model[name].predict_one(x)\n",
    "        variance = self.var[name].update(y_pred).get()\n",
    "\n",
    "        return np.random.normal(y_pred, variance**0.5, 225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12178ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gogo Coyote restarting at 2022-10-03 00:38:14.743772\n",
      "('{\"quietude\": 50, \"stop_loss\": 10, \"min_lags\": 25, \"num_active\": 15, '\n",
      " '\"num_pending_cancellations\": 0, \"current_balance\": -794.4710584743575, '\n",
      " '\"recent_errors\": [], \"currently_worst\": [], \"pending_cancellations\": [], '\n",
      " '\"upcoming\": [[\"70::yarx_dgx.json\", -1.2], [\"70::yarx_algn.json\", -0.2], '\n",
      " '[\"70::xray_162.json\", 0.7]]}')\n",
      "Gogo Coyote has active submissions for 15 horizons (15 with no withdrawal request pending since restart)\n",
      "Received recent confirmation of 4 requests to withdraw predictions and 4 confirmed cancellations.\n",
      "Upcoming horizons and seconds to go ...\n",
      "[('70::yarx_dgx.json', -1.7),\n",
      " ('70::yarx_algn.json', -0.7),\n",
      " ('70::xray_162.json', 0.2),\n",
      " ('910::yarx_vac.json', 5.2),\n",
      " ('70::noaa_wind_direction_46061.json', 6.2)]\n",
      "('{\"quietude\": 50, \"stop_loss\": 10, \"min_lags\": 25, \"num_active\": 15, '\n",
      " '\"num_pending_cancellations\": 0, \"current_balance\": -794.4710584743575, '\n",
      " '\"recent_errors\": [], \"currently_worst\": [], \"pending_cancellations\": [], '\n",
      " '\"upcoming\": [[\"70::yarx_dgx.json\", -3.2], [\"70::yarx_algn.json\", -2.2], '\n",
      " '[\"70::xray_162.json\", -1.2]]}')\n",
      "-------------------------------------------------------------\n",
      "Just a reminder ... \n",
      "Your write key is 7248d354a9e2a4aac6feb7dcc433acb1\n",
      "Your public key is 9090c0407e082083fc2dc0b2752e5775\n",
      "Your nom de plume is Gogo Coyote\n",
      "Put your write key in the dashboard at www.microprediction.org\n",
      "--------------------------------------------------------------\n",
      "Checking performance \n",
      "Currently predicting for 15 horizons but found 4647 candidate streams to examine.\n",
      "Submitted to yarx_al.json 310s horizon, and will do so again in 2407 seconds.\n",
      "Submitted to horizon 310::yarx_al.json\n",
      "Downtime for 1.2000000000000002s\n",
      "Gogo Coyote has active submissions for 15 horizons (15 with no withdrawal request pending since restart)\n",
      "Received recent confirmation of 4 requests to withdraw predictions and 4 confirmed cancellations.\n",
      "Upcoming horizons and seconds to go ...\n",
      "[('70::z3~noaa_wind_direction_41008~noaa_wind_speed_41008~noaa_wind_speed_44005~3555.json',\n",
      "  1.7),\n",
      " ('70::z1~naafg_6~3555.json', 6.7),\n",
      " ('310::z1~tour_6_bad~3555.json', 11.7),\n",
      " ('310::z1~gnaaf_33333~3555.json', 31.7),\n",
      " ('70::z2~noaa_wind_direction_46077~noaa_wind_speed_46073~70.json', 36.7)]\n",
      "Downtime for 1.1s\n",
      "Gogo Coyote has active submissions for 15 horizons (15 with no withdrawal request pending since restart)\n",
      "Received recent confirmation of 4 requests to withdraw predictions and 4 confirmed cancellations.\n",
      "Upcoming horizons and seconds to go ...\n",
      "[('70::z1~naafg_6~3555.json', 1.5),\n",
      " ('310::z1~tour_6_bad~3555.json', 6.5),\n",
      " ('310::z1~gnaaf_33333~3555.json', 26.5),\n",
      " ('70::z2~noaa_wind_direction_46077~noaa_wind_speed_46073~70.json', 31.5),\n",
      " ('70::yarx_dgx.json', 53.2)]\n",
      "Downtime for 1.2999999999999998s\n",
      "Gogo Coyote has active submissions for 15 horizons (15 with no withdrawal request pending since restart)\n",
      "Received recent confirmation of 4 requests to withdraw predictions and 4 confirmed cancellations.\n",
      "Upcoming horizons and seconds to go ...\n",
      "[('310::z1~tour_6_bad~3555.json', 1.7),\n",
      " ('310::z1~gnaaf_33333~3555.json', 21.7),\n",
      " ('70::z2~noaa_wind_direction_46077~noaa_wind_speed_46073~70.json', 26.7),\n",
      " ('70::yarx_dgx.json', 48.3),\n",
      " ('70::yarx_algn.json', 48.7)]\n",
      "Downtime for 16.3s\n",
      "Gogo Coyote has active submissions for 15 horizons (15 with no withdrawal request pending since restart)\n",
      "Received recent confirmation of 4 requests to withdraw predictions and 4 confirmed cancellations.\n",
      "Upcoming horizons and seconds to go ...\n",
      "[('310::z1~gnaaf_33333~3555.json', 16.7),\n",
      " ('70::z2~noaa_wind_direction_46077~noaa_wind_speed_46073~70.json', 21.7),\n",
      " ('70::yarx_dgx.json', 43.4),\n",
      " ('70::yarx_algn.json', 43.7),\n",
      " ('70::xray_162.json', 44.0)]\n",
      "Downtime for 1.2999999999999998s\n",
      "Gogo Coyote has active submissions for 15 horizons (15 with no withdrawal request pending since restart)\n",
      "Received recent confirmation of 4 requests to withdraw predictions and 4 confirmed cancellations.\n",
      "Upcoming horizons and seconds to go ...\n",
      "[('70::z2~noaa_wind_direction_46077~noaa_wind_speed_46073~70.json', 1.7),\n",
      " ('70::yarx_dgx.json', 23.3),\n",
      " ('70::yarx_algn.json', 23.7),\n",
      " ('70::xray_162.json', 24.0),\n",
      " ('70::noaa_wind_direction_46061.json', 24.9)]\n",
      "Downtime for 17.8s\n",
      "Gogo Coyote has active submissions for 15 horizons (15 with no withdrawal request pending since restart)\n",
      "Received recent confirmation of 4 requests to withdraw predictions and 4 confirmed cancellations.\n",
      "Upcoming horizons and seconds to go ...\n",
      "[('70::yarx_dgx.json', 18.2),\n",
      " ('70::yarx_algn.json', 18.5),\n",
      " ('70::xray_162.json', 18.8),\n",
      " ('70::noaa_wind_direction_46061.json', 19.7),\n",
      " ('70::xray_601.json', 20.8)]\n",
      "Currently predicting for 15 horizons but found 4647 candidate streams to examine.\n",
      "Submitted to gnaaf_01444.json 70s horizon, and will do so again in 910 seconds.\n",
      "Submitted to horizon 70::gnaaf_01444.json\n",
      "Downtime for 26.4s\n",
      "Gogo Coyote has active submissions for 15 horizons (15 with no withdrawal request pending since restart)\n",
      "Received recent confirmation of 4 requests to withdraw predictions and 4 confirmed cancellations.\n",
      "Upcoming horizons and seconds to go ...\n",
      "[('70::z2~noaa_wind_direction_46077~noaa_wind_speed_46073~70.json', 26.8),\n",
      " ('70::yarx_dgx.json', 48.5),\n",
      " ('70::yarx_algn.json', 48.8),\n",
      " ('70::xray_162.json', 49.1),\n",
      " ('70::noaa_wind_direction_46061.json', 49.9)]\n",
      "Downtime for 17.8s\n",
      "Gogo Coyote has active submissions for 15 horizons (15 with no withdrawal request pending since restart)\n",
      "Received recent confirmation of 4 requests to withdraw predictions and 4 confirmed cancellations.\n",
      "Upcoming horizons and seconds to go ...\n",
      "[('70::yarx_dgx.json', 18.2),\n",
      " ('70::yarx_algn.json', 18.6),\n",
      " ('70::xray_162.json', 18.9),\n",
      " ('70::noaa_wind_direction_46061.json', 19.7),\n",
      " ('70::xray_601.json', 20.8)]\n",
      "Downtime for 2.1s\n",
      "Gogo Coyote has active submissions for 15 horizons (15 with no withdrawal request pending since restart)\n"
     ]
    }
   ],
   "source": [
    "mw = MyCrawler(write_key = '7248d354a9e2a4aac6feb7dcc433acb1')\n",
    "mw.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24d52b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
