{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# !pip install river"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"hospital_wait.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "dataset.head()\n",
    "print(type(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'converters': {'value': float},'parse_dates': {'time': \"%Y-%m-%d %H:%M:%S\"}}\n",
    "\n",
    "dataset = dict()\n",
    "from river import stream\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import compose\n",
    "from river import linear_model\n",
    "from river import metrics\n",
    "from river import evaluate\n",
    "from river import preprocessing\n",
    "from river import feature_extraction\n",
    "from river import stats\n",
    "from river import optim\n",
    "from river import facto\n",
    "from river import model_selection\n",
    "from river import time_series\n",
    "from river import tree\n",
    "from river import dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "hour_list = [str(i) for i in range (0,24)]\n",
    "minute_list = [f'{str(i)} min' for i in range (0, 60)]\n",
    "def get_hour(x):\n",
    "    x['h'] = x['time'].hour\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_minute(x):\n",
    "    x['m'] = x['time'].minute//15 + 1\n",
    "    return x\n",
    "\n",
    "def get_day(x):\n",
    "    \n",
    "    return {'d' : x['time'].day}\n",
    "\n",
    "def get_hour_sin_and_cos(x):\n",
    "    return {'sin_h' : np.sin(np.pi*(x['time'].hour)/12), 'cos_h': np.cos(np.pi*(x['time'].hour)/12)}\n",
    "\n",
    "\n",
    "def get_minute_distances(x):\n",
    "    x['sin_m'] = np.sin(np.pi*(x['time'].minute)/30)\n",
    "    x['cos_m'] = np.cos(np.pi*(x['time'].minute)/30)\n",
    "    return {'sin_m' : np.sin(np.pi*(x['time'].minute)/30), 'cos_m': np.cos(np.pi*(x['time'].minute)/30)}\n",
    "\n",
    "def get_date_progress(x):\n",
    "    return {'date': x['time'].toordinal() - datetime.datetime(2022, 1, 1, 0, 0).toordinal()}\n",
    "\n",
    "i = 0\n",
    "temp = [323,323,323,323]\n",
    "cache = [temp]\n",
    "my_dict = {}\n",
    "for x, y in stream.iter_csv('hospital_wait.csv', target = 'value', **params):\n",
    "    if i < 4:\n",
    "        t = temp.copy()\n",
    "        t[i] = y\n",
    "        cache.append(t)      \n",
    "        temp = t\n",
    "        my_dict[x['time']] = t\n",
    "    else:\n",
    "        t = temp.copy()\n",
    "        t.pop(0)\n",
    "        t.append(y)\n",
    "        cache.append(t)\n",
    "        temp = t\n",
    "        my_dict[x['time']] = t\n",
    "    i += 1\n",
    "\n",
    "\n",
    "\n",
    "def get_lag(x):\n",
    "    lag_values = my_dict[x['time']]\n",
    "    return {'lag_1': lag_values[0], 'lag_2': lag_values[1], 'lag_3': lag_values[2], 'lag_4': lag_values[3]}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_linear(pipeline, optimizer=None):\n",
    "    model = pipeline\n",
    "    if optimizer:\n",
    "        model |= linear_model.LinearRegression(intercept_lr=.1, optimizer = optimizer)\n",
    "    else:\n",
    "        model |= linear_model.LinearRegression(intercept_lr=.1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = [linear_model.LinearRegression(optimizer=optim.SGD(lr=lr)) for lr in [0.05, 0.02, 0.01, 0.005, 0.002, 0.0001]]\n",
    "\n",
    "\n",
    "model = compose.Pipeline(\n",
    "    ('features', compose.TransformerUnion(\n",
    "        ('date_progress', compose.FuncTransformer(get_date_progress)),\n",
    "        ('lags', compose.FuncTransformer(get_lag))\n",
    "    )))\n",
    "\n",
    "model += (\n",
    "    get_hour | \n",
    "        feature_extraction.TargetAgg(\n",
    "            by=['h'], how=stats.Mean()\n",
    "\n",
    "\n",
    "))\n",
    "model += (\n",
    "    get_minute | \n",
    "        feature_extraction.TargetAgg(\n",
    "            by=['m'], how=stats.Mean()\n",
    "\n",
    "\n",
    "))\n",
    "\n",
    "model |=  preprocessing.StandardScaler()\n",
    "# model |= linear_model.LinearRegression(intercept_lr=.1)\n",
    "\n",
    "\n",
    "# model |=  model_selection.EpsilonGreedyRegressor(models, epsilon=0.025, decay=0.1, burn_in=100, seed=1)\n",
    "# model |= tree.HoeffdingAdaptiveTreeRegressor(grace_period=100, leaf_prediction='adaptive', model_selector_decay=0.9, seed=0)\n",
    "# model = preprocessing.TargetStandardScaler(regressor=model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50] MAE: 45.879082, R2: -0.004024\n",
      "[100] MAE: 36.566037, R2: 0.694548\n",
      "[150] MAE: 27.610535, R2: 0.818795\n",
      "[200] MAE: 23.715372, R2: 0.838152\n",
      "[250] MAE: 20.122645, R2: 0.860365\n",
      "[300] MAE: 18.389003, R2: 0.88454\n",
      "[350] MAE: 16.422354, R2: 0.912944\n",
      "[400] MAE: 15.160021, R2: 0.92184\n",
      "[450] MAE: 14.434028, R2: 0.92707\n",
      "[500] MAE: 13.822398, R2: 0.932736\n",
      "[550] MAE: 12.841361, R2: 0.938584\n",
      "[600] MAE: 12.427435, R2: 0.941154\n",
      "[650] MAE: 11.665425, R2: 0.946559\n",
      "[700] MAE: 10.994886, R2: 0.948179\n",
      "[750] MAE: 10.445997, R2: 0.951443\n",
      "[800] MAE: 9.965217, R2: 0.952663\n",
      "[850] MAE: 9.590534, R2: 0.956341\n",
      "[900] MAE: 9.162267, R2: 0.958786\n",
      "[950] MAE: 8.888767, R2: 0.961491\n",
      "[1,000] MAE: 8.593528, R2: 0.962387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'y_mean_by_m': -0.9807493324966388,\n",
       " 'y_mean_by_h': -1.2949853252408325,\n",
       " 'lag_1': -0.7824379451711704,\n",
       " 'lag_2': -0.7807918309726335,\n",
       " 'lag_3': -0.7347856615567347,\n",
       " 'lag_4': -0.7332484358217568,\n",
       " 'date': 1.8460647891520903}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = metrics.MAE() + metrics.R2()\n",
    "evaluate.progressive_val_score(stream.iter_csv('hospital_wait.csv', target = 'value', **params), make_linear(model), metric, print_every=50)\n",
    "# evaluate.progressive_val_score(stream.iter_csv('hospital_wait.csv', target = 'value', **params), dummy.StatisticRegressor(stats.Shift(1)), metric, print_every=50)\n",
    "model.transform_one(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50] MAE: 10.900357, R2: 0.937807\n",
      "[100] MAE: 13.020433, R2: 0.92481\n",
      "[150] MAE: 13.709595, R2: 0.922444\n",
      "[200] MAE: 15.077885, R2: 0.917045\n",
      "[250] MAE: 15.38864, R2: 0.915097\n",
      "[300] MAE: 16.453746, R2: 0.908695\n",
      "[350] MAE: 16.504566, R2: 0.90819\n",
      "[400] MAE: 17.055613, R2: 0.905723\n",
      "[450] MAE: 17.632432, R2: 0.90363\n",
      "[500] MAE: 18.298425, R2: 0.900693\n",
      "[550] MAE: 18.132511, R2: 0.901909\n",
      "[600] MAE: 18.701719, R2: 0.896317\n",
      "[650] MAE: 18.384302, R2: 0.8991\n",
      "[700] MAE: 18.447953, R2: 0.898513\n",
      "[750] MAE: 18.56945, R2: 0.898439\n",
      "[800] MAE: 18.60872, R2: 0.898174\n",
      "[850] MAE: 18.8057, R2: 0.898835\n",
      "[900] MAE: 18.830628, R2: 0.899834\n",
      "[950] MAE: 18.973025, R2: 0.899999\n",
      "[1,000] MAE: 19.067957, R2: 0.899113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MAE: 19.067957, R2: 0.899113"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate.progressive_val_score(stream.iter_csv('hospital_wait.csv', target = 'value', **params), make_linear(model, optim.AMSGrad()), metric, print_every=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50] MAE: 20.003544, R2: 0.887407\n",
      "[100] MAE: 20.959441, R2: 0.883191\n",
      "[150] MAE: 21.199265, R2: 0.882055\n",
      "[200] MAE: 21.870961, R2: 0.87963\n",
      "[250] MAE: 21.957461, R2: 0.878298\n",
      "[300] MAE: 22.54175, R2: 0.874101\n",
      "[350] MAE: 22.521101, R2: 0.873612\n",
      "[400] MAE: 22.859125, R2: 0.871535\n",
      "[450] MAE: 23.197518, R2: 0.870005\n",
      "[500] MAE: 23.63944, R2: 0.867683\n",
      "[550] MAE: 23.491418, R2: 0.868462\n",
      "[600] MAE: 23.871411, R2: 0.863874\n",
      "[650] MAE: 23.610801, R2: 0.866027\n",
      "[700] MAE: 23.669135, R2: 0.865163\n",
      "[750] MAE: 23.800724, R2: 0.864285\n",
      "[800] MAE: 23.843014, R2: 0.863761\n",
      "[850] MAE: 24.019836, R2: 0.86341\n",
      "[900] MAE: 24.106358, R2: 0.863575\n",
      "[950] MAE: 24.267559, R2: 0.862516\n",
      "[1,000] MAE: 24.402022, R2: 0.861135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MAE: 24.402022, R2: 0.861135"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate.progressive_val_score(stream.iter_csv('hospital_wait.csv', target = 'value', **params), make_linear(model, optim.AdaMax()), metric, print_every=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50] MAE: 8,559,925.680405, R2: -2,280,640,855,808.125488\n",
      "[100] MAE: 5,168,516,862.146273, R2: -365,726,910,050,027,264.\n",
      "[150] MAE: 11,684,481,521.879799, R2: -765,857,359,835,622,656.\n",
      "[200] MAE: 13,021,669,960.02702, R2: -765,732,661,103,516,800.\n",
      "[250] MAE: 15,932,287,423.780483, R2: -866,877,416,142,424,448.\n",
      "[300] MAE: 20,223,738,313.502239, R2: -1,051,351,845,618,932,736.\n",
      "[350] MAE: 33,586,929,534.451107, R2: -1,782,200,783,362,059,776.\n",
      "[400] MAE: 36,099,868,764.819435, R2: -1,862,249,576,205,182,976.\n",
      "[450] MAE: 37,873,016,190.13961, R2: -1,920,548,239,264,868,608.\n",
      "[500] MAE: 40,190,785,601.061897, R2: -2,040,322,328,215,726,592.\n",
      "[550] MAE: 46,031,425,078.601448, R2: -2,238,722,521,546,386,432.\n",
      "[600] MAE: 48,681,830,150.416641, R2: -2,308,128,699,321,106,432.\n",
      "[650] MAE: 58,569,073,699.093475, R2: -2,769,104,415,200,223,232.\n",
      "[700] MAE: 57,817,969,585.02079, R2: -2,748,390,399,962,011,648.\n",
      "[750] MAE: 64,007,297,062.187157, R2: -3,005,706,265,930,449,920.\n",
      "[800] MAE: 63,483,562,497.891022, R2: -2,985,898,173,790,823,424.\n",
      "[850] MAE: 69,213,666,207.091553, R2: -3,355,001,695,044,506,112.\n",
      "[900] MAE: 73,644,027,881.540939, R2: -3,552,006,091,245,274,624.\n",
      "[950] MAE: 80,473,375,767.869507, R2: -3,880,762,897,855,024,128.\n",
      "[1,000] MAE: 79,925,036,146.241592, R2: -3,853,296,390,727,595,008.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGD({'lr': Constant({'learning_rate': 0.1}), 'n_iterations': 0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate.progressive_val_score(stream.iter_csv('hospital_wait.csv', target = 'value', **params), make_linear(model, optim.SGD(0.1)), metric, print_every=50)\n",
    "optim.SGD(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50] MAE: 59,203,749,741.711433, R2: -2,871,156,824,588,147,200.\n",
      "[100] MAE: 58,640,530,785.481369, R2: -2,767,489,139,922,445,824.\n",
      "[150] MAE: 58,315,060,991.175331, R2: -2,750,831,297,366,760,960.\n",
      "[200] MAE: 59,972,305,563.013306, R2: -2,846,261,279,746,800,640.\n",
      "[250] MAE: 70,866,516,239.097549, R2: -4,590,995,181,177,077,760.\n",
      "[300] MAE: 109,302,798,983.656387, R2: -22,634,570,180,669,104,128.\n",
      "[350] MAE: 124,632,512,588.713425, R2: -25,848,916,491,619,618,816.\n",
      "[400] MAE: 194,058,988,516.042633, R2: -69,389,790,511,187,697,664.\n",
      "[450] MAE: 251,933,165,095.091949, R2: -113,759,927,129,072,418,816.\n",
      "[500] MAE: 286,657,576,219.223633, R2: -140,762,825,526,725,443,584.\n",
      "[550] MAE: 303,198,403,227.450989, R2: -144,403,048,360,930,394,112.\n",
      "[600] MAE: 332,391,567,458.433899, R2: -153,503,194,495,734,022,144.\n",
      "[650] MAE: 349,128,567,802.829834, R2: -157,011,154,800,823,369,728.\n",
      "[700] MAE: 362,224,191,082.246094, R2: -160,531,415,141,834,358,784.\n",
      "[750] MAE: 387,424,149,155.195007, R2: -168,164,569,934,840,791,040.\n",
      "[800] MAE: 452,676,404,345.963379, R2: -229,721,732,295,807,401,984.\n",
      "[850] MAE: 631,767,208,825.10083, R2: -680,764,005,264,449,077,248.\n",
      "[900] MAE: 746,931,529,919.172852, R2: -849,560,273,965,917,011,968.\n",
      "[950] MAE: 954,345,900,134.553833, R2: -1,532,543,061,120,188,678,144.\n",
      "[1,000] MAE: 1,074,015,630,172.842285, R2: -1,709,720,221,086,712,856,576.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MAE: 1,074,015,630,172.842285, R2: -1,709,720,221,086,712,856,576."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate.progressive_val_score(stream.iter_csv('hospital_wait.csv', target = 'value', **params), make_linear(model, optim.Momentum()), metric, print_every=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "\n",
    "\n",
    "queue = collections.deque([], 4)\n",
    "\n",
    "def evaluate_model(model): \n",
    "\n",
    "    metric = metrics.Rolling(metrics.MAE(), 10)\n",
    "    metric_b = metrics.Rolling(metrics.MAE(), 10)\n",
    "    \n",
    "    dates = []\n",
    "    y_trues = []\n",
    "    y_preds = []\n",
    "    \n",
    "    baseline = 0\n",
    "    y_baseline = []\n",
    "    for x, y in stream.iter_csv('hospital_wait.csv', target = 'value', **params):\n",
    "        \n",
    "        new_feats = {f\"lag_{i}\": v for i, v in enumerate(queue)}\n",
    "\n",
    "        # copy of x\n",
    "        x_ = dict(x)\n",
    "        x_.update(new_feats)\n",
    "\n",
    "        y_pred = model.predict_one(x_)\n",
    "        model.learn_one(x_, y)\n",
    "\n",
    "        queue.append(y)\n",
    "\n",
    "        # Obtain the prior prediction and update the model in one go\n",
    "        y_pred = model.predict_one(x)\n",
    "        model.learn_one(x, y)\n",
    "\n",
    "        # Update the error metric\n",
    "        metric.update(y, y_pred)\n",
    "        metric_b.update(y, baseline)\n",
    "        \n",
    "        # Store the true value and the prediction\n",
    "        dates.append(x['time'])\n",
    "        y_trues.append(y)\n",
    "        y_preds.append(y_pred)\n",
    "        y_baseline.append(baseline)\n",
    "        baseline = y\n",
    "        \n",
    "    print(metric, metric_b)\n",
    "\n",
    "    # Plot the results\n",
    "    fig, ax = plt.subplots(figsize=(20, 6))\n",
    "    ax.grid(alpha=0.75)\n",
    "    ax.plot(dates, y_trues, lw=3, color='#2ecc71', alpha=800, label='Ground truth')\n",
    "    ax.plot(dates, y_preds, lw=3, color='#e74c3c', alpha=800, label='Prediction')\n",
    "    ax.plot(dates, y_baseline, lw=3, color='#e74c3c', alpha=800, label='Baseline')\n",
    "    ax.legend()\n",
    "    ax.set_title(metric)\n",
    "evaluate_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(alpha):\n",
    "    models = [linear_model.LinearRegression(optimizer=optim.SGD(lr=lr), loss=optim.losses.Quantile(alpha=alpha)) for lr in [0.05, 0.02, 0.01, 0.005, 0.002, 0.0001]]\n",
    "\n",
    "\n",
    "    model = compose.Pipeline(\n",
    "        ('features', compose.TransformerUnion(\n",
    "            ('date_progress', compose.FuncTransformer(get_date_progress)),\n",
    "            ('lags', compose.FuncTransformer(get_lag))\n",
    "        )))\n",
    "\n",
    "    model += (\n",
    "        get_hour | \n",
    "            feature_extraction.TargetAgg(\n",
    "                by=['h'], how=stats.Mean()\n",
    "\n",
    "\n",
    "    ))\n",
    "    # model += (\n",
    "    #     get_minute | \n",
    "    #         feature_extraction.TargetAgg(\n",
    "    #             by=['m'], how=stats.Mean()\n",
    "\n",
    "\n",
    "    # ))\n",
    "\n",
    "    model |=  preprocessing.StandardScaler()\n",
    "    model |= preprocessing.TargetStandardScaler( \n",
    "        model_selection.UCBRegressor(\n",
    "            models,\n",
    "            delta=0.01, burn_in=100, seed=1\n",
    "        )\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'lower': make_model(alpha=0.05),\n",
    "    'center': make_model(alpha=0.5),\n",
    "    'upper': make_model(alpha=0.95)\n",
    "}\n",
    "\n",
    "dates = []\n",
    "y_trues = []\n",
    "y_preds = {\n",
    "    'lower': [],\n",
    "    'center': [],\n",
    "    'upper': []\n",
    "}\n",
    "\n",
    "for x, y in stream.iter_csv('hospital_wait.csv', target = 'value', **params):\n",
    "    y_trues.append(y)\n",
    "    dates.append(x['time'])\n",
    "\n",
    "    for name, model in models.items():\n",
    "        y_preds[name].append(model.predict_one(x))\n",
    "        model.learn_one(x, y)\n",
    "\n",
    "    # Update the error metric\n",
    "    metric.update(y, y_preds['center'][-1])\n",
    "\n",
    "# Plot the results\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.grid(alpha=0.75)\n",
    "ax.plot(dates, y_trues, lw=3, color='#2ecc71', alpha=0.8, label='Truth')\n",
    "ax.plot(dates, y_preds['center'], lw=3, color='#e74c3c', alpha=0.8, label='Prediction')\n",
    "ax.fill_between(dates, y_preds['lower'], y_preds['upper'], color='#e74c3c', alpha=0.3, label='Prediction interval')\n",
    "ax.legend()\n",
    "ax.set_title(metric);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
