{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: river in c:\\users\\this pc\\anaconda3\\lib\\site-packages (0.11.1)\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\users\\this pc\\anaconda3\\lib\\site-packages (from river) (1.23.1)\n",
      "Requirement already satisfied: scipy>=1.5 in c:\\users\\this pc\\anaconda3\\lib\\site-packages (from river) (1.5.2)\n",
      "Requirement already satisfied: pandas>=1.3 in c:\\users\\this pc\\anaconda3\\lib\\site-packages (from river) (1.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\this pc\\anaconda3\\lib\\site-packages (from pandas>=1.3->river) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\this pc\\anaconda3\\lib\\site-packages (from pandas>=1.3->river) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\this pc\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.3->river) (1.15.0)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'hospital_wait.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8e4cb138e45c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip install river'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"hospital_wait.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1216\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1218\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1219\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hospital_wait.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "!pip install river\n",
    "\n",
    "dataset = pd.read_csv(\"hospital_wait.csv\")\n",
    "\n",
    "dataset.head()\n",
    "print(type(dataset))\n",
    "\n",
    "params = {'converters': {'value': float},'parse_dates': {'time': \"%Y-%m-%d %H:%M:%S\"}}\n",
    "\n",
    "dataset = dict()\n",
    "from river import stream\n",
    "for x, y in stream.iter_csv('hospital_wait.csv', target = 'value', **params):\n",
    "    print(x,y)\n",
    "\n",
    "from river import compose\n",
    "from river import linear_model\n",
    "from river import metrics\n",
    "from river import evaluate\n",
    "from river import preprocessing\n",
    "from river import feature_extraction\n",
    "from river import stats\n",
    "from river import optim\n",
    "from river import facto\n",
    "from river import model_selection\n",
    "from river import time_series\n",
    "from river import tree\n",
    "from river import dummy\n",
    "\n",
    "import math\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "hour_list = [str(i) for i in range (0,24)]\n",
    "minute_list = [f'{str(i)} min' for i in range (0, 60)]\n",
    "def get_hour(x):\n",
    "    x['h'] = x['time'].hour\n",
    "    return x\n",
    "print(get_hour({'time': datetime.datetime(2022, 7, 22, 15, 3, 37)}))\n",
    "\n",
    "def get_minute(x):\n",
    "    x['m'] = x['time'].minute//15 + 1\n",
    "    return x\n",
    "\n",
    "def get_day(x):\n",
    "    \n",
    "    return {'d' : x['time'].day}\n",
    "\n",
    "def get_hour_sin_and_cos(x):\n",
    "    x['sin_h'] = np.sin(np.pi*(x['time'].hour)/12) \n",
    "    x['cos_h'] = np.cos(np.pi*(x['time'].hour)/12)\n",
    "    return {'sin_h' : np.sin(np.pi*(x['time'].hour)/12), 'cos_h': np.cos(np.pi*(x['time'].hour)/12)}\n",
    "print(get_hour_sin_and_cos({'time': datetime.datetime(2022, 7, 22, 6, 3, 37)}))\n",
    "\n",
    "def get_minute_distances(x):\n",
    "    x['sin_m'] = np.sin(np.pi*(x['time'].minute)/30)\n",
    "    x['cos_m'] = np.cos(np.pi*(x['time'].minute)/30)\n",
    "    return {'sin_m' : np.sin(np.pi*(x['time'].minute)/30), 'cos_m': np.cos(np.pi*(x['time'].minute)/30)}\n",
    "\n",
    "def get_date_progress(x):\n",
    "    return {'date': x['time'].toordinal() - datetime.datetime(2022, 1, 1, 0, 0).toordinal()}\n",
    "\n",
    "i = 0\n",
    "temp = [323,323,323,323]\n",
    "cache = [temp]\n",
    "my_dict = {}\n",
    "print(cache)\n",
    "for x, y in stream.iter_csv('hospital_wait.csv', target = 'value', **params):\n",
    "    print(x)\n",
    "    if i < 4:\n",
    "        t = temp.copy()\n",
    "        t[i] = y\n",
    "        cache.append(t)      \n",
    "        temp = t\n",
    "        my_dict[x['time']] = t\n",
    "    else:\n",
    "        t = temp.copy()\n",
    "        t.pop(0)\n",
    "        t.append(y)\n",
    "        cache.append(t)\n",
    "        temp = t\n",
    "        my_dict[x['time']] = t\n",
    "    i += 1\n",
    "\n",
    "print(my_dict)\n",
    "\n",
    "def get_lag(x):\n",
    "    lag_values = my_dict[x['time']]\n",
    "    return {'lag_1': lag_values[0], 'lag_2': lag_values[1], 'lag_3': lag_values[2], 'lag_4': lag_values[3]}\n",
    "    \n",
    "\n",
    "\n",
    "models = [linear_model.LinearRegression(optimizer=optim.SGD(lr=lr)) for lr in [0.05, 0.02, 0.01, 0.005, 0.002, 0.0001]]\n",
    "\n",
    "\n",
    "model = compose.Pipeline(\n",
    "    ('features', compose.TransformerUnion(\n",
    "        ('date_progress', compose.FuncTransformer(get_date_progress))\n",
    "#         ('lags', compose.FuncTransformer(get_lag))\n",
    "    )))\n",
    "\n",
    "model += (\n",
    "    get_hour | \n",
    "        feature_extraction.TargetAgg(\n",
    "            by=['h'], how=stats.Mean()\n",
    "\n",
    "\n",
    "))\n",
    "model += (\n",
    "    get_minute | \n",
    "        feature_extraction.TargetAgg(\n",
    "            by=['m'], how=stats.Mean()\n",
    "\n",
    "\n",
    "))\n",
    "\n",
    "model |=  preprocessing.StandardScaler()\n",
    "model |= preprocessing.TargetStandardScaler( \n",
    "    model_selection.UCBRegressor(\n",
    "        models + \n",
    "        [\n",
    "            tree.HoeffdingTreeRegressor(grace_period=20),\n",
    "            linear_model.PARegressor(C=0.012, eps=0.05),\n",
    "        ],\n",
    "        delta=0.01, burn_in=100, seed=1\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# model |=  model_selection.EpsilonGreedyRegressor(models, epsilon=0.025, decay=0.1, burn_in=100, seed=1)\n",
    "# model |= tree.HoeffdingAdaptiveTreeRegressor(grace_period=100, leaf_prediction='adaptive', model_selector_decay=0.9, seed=0)\n",
    "# model = preprocessing.TargetStandardScaler(regressor=model)\n",
    "\n",
    "\n",
    "\n",
    "metric = metrics.MAE() + metrics.R2()\n",
    "evaluate.progressive_val_score(stream.iter_csv('hospital_wait.csv', target = 'value', **params), model, metric, print_every=50)\n",
    "# evaluate.progressive_val_score(stream.iter_csv('hospital_wait.csv', target = 'value', **params), dummy.StatisticRegressor(stats.Shift(1)), metric, print_every=50)\n",
    "model.transform_one(x)\n",
    "\n",
    "from river import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "\n",
    "\n",
    "queue = collections.deque([], 4)\n",
    "\n",
    "def evaluate_model(model): \n",
    "\n",
    "    metric = metrics.Rolling(metrics.MAE(), 10)\n",
    "    metric_b = metrics.Rolling(metrics.MAE(), 10)\n",
    "    \n",
    "    dates = []\n",
    "    y_trues = []\n",
    "    y_preds = []\n",
    "    \n",
    "    baseline = 0\n",
    "    y_baseline = []\n",
    "    for x, y in stream.iter_csv('hospital_wait.csv', target = 'value', **params):\n",
    "        \n",
    "        new_feats = {f\"lag_{i}\": v for i, v in enumerate(queue)}\n",
    "\n",
    "        # copy of x\n",
    "        x_ = dict(x)\n",
    "        x_.update(new_feats)\n",
    "\n",
    "        y_pred = model.predict_one(x_)\n",
    "        model.learn_one(x_, y)\n",
    "\n",
    "        queue.append(y)\n",
    "\n",
    "        # Obtain the prior prediction and update the model in one go\n",
    "        y_pred = model.predict_one(x)\n",
    "        model.learn_one(x, y)\n",
    "\n",
    "        # Update the error metric\n",
    "        metric.update(y, y_pred)\n",
    "        metric_b.update(y, baseline)\n",
    "        \n",
    "        # Store the true value and the prediction\n",
    "        dates.append(x['time'])\n",
    "        y_trues.append(y)\n",
    "        y_preds.append(y_pred)\n",
    "        y_baseline.append(baseline)\n",
    "        baseline = y\n",
    "        \n",
    "    print(metric, metric_b)\n",
    "\n",
    "    # Plot the results\n",
    "    fig, ax = plt.subplots(figsize=(20, 6))\n",
    "    ax.grid(alpha=0.75)\n",
    "    ax.plot(dates, y_trues, lw=3, color='#2ecc71', alpha=800, label='Ground truth')\n",
    "    ax.plot(dates, y_preds, lw=3, color='#e74c3c', alpha=800, label='Prediction')\n",
    "    ax.plot(dates, y_baseline, lw=3, color='#e74c3c', alpha=800, label='Baseline')\n",
    "    ax.legend()\n",
    "    ax.set_title(metric)\n",
    "evaluate_model(model)\n",
    "\n",
    "\n",
    "def make_model(alpha):\n",
    "    models = [linear_model.LinearRegression(optimizer=optim.SGD(lr=lr), loss=optim.losses.Quantile(alpha=alpha)) for lr in [0.05, 0.02, 0.01, 0.005, 0.002, 0.0001]]\n",
    "\n",
    "\n",
    "    model = compose.Pipeline(\n",
    "        ('features', compose.TransformerUnion(\n",
    "            ('date_progress', compose.FuncTransformer(get_date_progress)),\n",
    "            ('lags', compose.FuncTransformer(get_lag))\n",
    "        )))\n",
    "\n",
    "    model += (\n",
    "        get_hour | \n",
    "            feature_extraction.TargetAgg(\n",
    "                by=['h'], how=stats.Mean()\n",
    "\n",
    "\n",
    "    ))\n",
    "    # model += (\n",
    "    #     get_minute | \n",
    "    #         feature_extraction.TargetAgg(\n",
    "    #             by=['m'], how=stats.Mean()\n",
    "\n",
    "\n",
    "    # ))\n",
    "\n",
    "    model |=  preprocessing.StandardScaler()\n",
    "    model |= preprocessing.TargetStandardScaler( \n",
    "        model_selection.UCBRegressor(\n",
    "            models,\n",
    "            delta=0.01, burn_in=100, seed=1\n",
    "        )\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "models = {\n",
    "    'lower': make_model(alpha=0.05),\n",
    "    'center': make_model(alpha=0.5),\n",
    "    'upper': make_model(alpha=0.95)\n",
    "}\n",
    "\n",
    "dates = []\n",
    "y_trues = []\n",
    "y_preds = {\n",
    "    'lower': [],\n",
    "    'center': [],\n",
    "    'upper': []\n",
    "}\n",
    "\n",
    "for x, y in stream.iter_csv('hospital_wait.csv', target = 'value', **params):\n",
    "    y_trues.append(y)\n",
    "    dates.append(x['time'])\n",
    "\n",
    "    for name, model in models.items():\n",
    "        y_preds[name].append(model.predict_one(x))\n",
    "        model.learn_one(x, y)\n",
    "\n",
    "    # Update the error metric\n",
    "    metric.update(y, y_preds['center'][-1])\n",
    "\n",
    "# Plot the results\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.grid(alpha=0.75)\n",
    "ax.plot(dates, y_trues, lw=3, color='#2ecc71', alpha=0.8, label='Truth')\n",
    "ax.plot(dates, y_preds['center'], lw=3, color='#e74c3c', alpha=0.8, label='Prediction')\n",
    "ax.fill_between(dates, y_preds['lower'], y_preds['upper'], color='#e74c3c', alpha=0.3, label='Prediction interval')\n",
    "ax.legend()\n",
    "ax.set_title(metric);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
